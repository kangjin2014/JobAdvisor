{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch batch write test\n",
    "### compiled by Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: https://elasticsearch-py.readthedocs.io/en/master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "'''\n",
    "put\n",
    "'''\n",
    "\n",
    "doc = {\n",
    "    'author': 'ryan',\n",
    "    'text': 'this guy is very handsome',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "\n",
    "res_in  = es.index(index=\"job_id\", doc_type='text', id=1, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'job_id', '_type': 'text', '_id': '1', '_version': 1, 'found': True, '_source': {'author': 'ryan', 'text': 'this guy is very handsome', 'timestamp': '2018-03-19T21:55:17.342367'}}\n"
     ]
    }
   ],
   "source": [
    "res_out = es.get(index=\"job_id\", doc_type='text', id=1)\n",
    "\n",
    "print(res_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscale Code - Batch w/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "'''\n",
    "put\n",
    "'''\n",
    "\n",
    "def put_element(title, company, description, job_id):\n",
    "    \n",
    "    doc = {'title': title,  \n",
    "           'company': company,\n",
    "           'description': description}\n",
    "    \n",
    "    res_in  = es.index(body=doc,\n",
    "                       index=\"job\", \n",
    "                       doc_type='text',\n",
    "                       id= job_id)\n",
    "    \n",
    "    res_out = es.get(index=\"job\",\n",
    "                     doc_type='text',\n",
    "                     id= job_id)\n",
    "    \n",
    "    #print('{} has been written into Elasticsearch'.format(res_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_element('data science', 'rbc', 'machine learning devops', 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/ds.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e07cb7216e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjob_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjob_company\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/ds.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_jobs = pd.read_csv('data/ds.csv')\n",
    "df_jobs.head(3)\n",
    "job_title = df_jobs.jobtitle\n",
    "job_company = df_jobs.company\n",
    "job_description = df_jobs.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_jobs.iterrows():\n",
    "    put_element(row['jobtitle'], row['company'], row['description'], row['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'job', '_type': 'text', '_id': '0', '_version': 2, 'found': True, '_source': {'title': 'AI / Machine Learning Scientist – Toronto AI Lab', 'company': 'LG Electronics', 'description': 'At LG we make products and services that make lives better  easier and happier through increased functionality and fun  Put simply  we offer the latest innovations to make “Life Good” – from home appliances  consumer electronics  vehicle components and mobile communications to business innovations in digital signage  air conditioning  solar and LED lighting  As a global leader  we strive for greatness in product leadership  market leadership and people leadership to realize our growth strategies  Talk about a mantra  Life’s Good with LG  AI Machine Learning Scientist – Toronto AI Lab LG is looking to push boundaries of AI to build innovative disruptive product and services solutions to realize LG’s global vision for a connected world  As a part of this initiative  LG has set up an Advanced AI organization in North America centered in Silicon Valley  We are looking to tap into the world class talent in Canada by establishing a first R&D  lab in Toronto  As part of LG’s North America AI initiative  we are looking for passionate and talented AI   Machine Learning scientists and engineers for our Toronto AI Lab to work closely with the global AI labs on novel and disruptive solutions that will shape out LG’s global vision for Connected Home  Connected Cars  IoT and Robotics  The candidate will work with multi disciplinary team in Silicon Valley  including data scientists  product managers and software developers  to design and launch AI products and solutions that help predict  personalize and transform lifestyles of LG’s global footprint of devices and users  Seniority will be commensurate with experience and accomplishments  AI research scientists will work on advanced research topic and challenging business problem in the machine learning  natural language understanding  machine perception and cyber physical systems  using emerging disruptive technologies  Research scientists and engineers will also design novel experiments  invent machine learning algorithms  and create prototype implementations  Research scientists and engineers are also encouraged to publish high quality papers and patents and collaborate with leading academic universities in this field  Principal Duties and Responsibilities  Develop AI machine learning solutions targeted towards disruptive opportunities for LG business  based on perception  computer vision  speech  audio  cyber physical systems  etc  Build novel machine learning AI algorithms to develop differentiating IP for LG Build quick Proof of Concepts (POC) and project ownership around projects that can demonstrate utilization  value and lead to scalable solutions Actively participate in the research and academic community by disseminating novel results in top conferences and journals Stay up to date on developments in the field and propose long term capability buildup Collaborate with other R&D  groups as well as business units within LG (around AI) while maintaining clear differentiation and value in our specific offerings  and leading the path of innovative value driven AI solutions  Leverage experience with systems  and application development to realize products offerings in multi disciplinary settings  Job Requirements  PhD in Computer Science  Electrical Engineering  statistics or related quantitative discipline with a focus on Machine Learning AI Reinforcement learning or related areas with at least 3 years of experience Strong background in two or more of the following areas  machine learning AI algorithms  computations statistical learning theory  scalable systems (e g  Spark  Hadoop)  large scale data analysis  optimization  functional analysis and deep learning  Strong publication record in top conferences and journals A demonstrable track record of developing novel algorithms  solutions and delivered deployed projects in the area preferred  Experience in deep learning frameworks (e g   Tensorflow  MxNet)  and Large scale optimization preferred  Hands on coding experience in two or more of C C    Python  Scala  Lua  Java  R  Matlab A sense of ambition and passion to change the world using AI and machine Learning Experience in autonomous driving  smart city home  IoT and application of AI Machine learning in the context of these domains preferred LG Electronics  USA Inc   LG Mobilecomm USA  Inc   LG Mobile Research USA LLC  and Zenith Electronics LLC provides equal employment opportunity to all individuals regardless of their race  color  creed  religion  gender  age  sexual orientation  national origin  disability  veteran status  or any other characteristic protected by state  federal  or local law  Further  the Company takes affirmative action to ensure that applicants are employed and employees are treated during employment without regard to any of these characteristics   IND123 \\u200b  LI SB1'}}\n"
     ]
    }
   ],
   "source": [
    "res_out = es.get(index=\"job\", doc_type='text', id=0)\n",
    "print(res_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:9200/job/text/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 10}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(index=\"job_id\")\n",
    "\n",
    "res = es.search(index=\"job_id\", body={\"query\": {\"match_all\": {}}})\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
