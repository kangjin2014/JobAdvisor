{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is to pull job postings from indeed.com.\n",
    "# The code is original from WeCloudData and improved by big data project team. \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # pip3 install beautifulsoup4\n",
    "import urllib\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import nltk # pip3 install nltk\n",
    "from nltk.corpus import stopwords\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header() is a good to have function, for web scraping usign 'request' library.f\n",
    "\n",
    "def headers():\n",
    "    i = random.randint(3,5)\n",
    "    j=random.randint(40,53)\n",
    "    x=random.randint(2,13)\n",
    "    url_base = 'https://www.indeed.ca/jobs?q='\n",
    "    headers ={\n",
    "            'User-Agent':'Mozilla/'+str(i)+'.0 (Macintosh; Intel Mac OS X 10.'+str(x)+'; rv:53.0) Gecko/20100101 Firefox/'+str(j)+'.0'\n",
    "                }\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_cleaner() consists of beautifulsoup, regular rexpression, unicode modules to covert HMTL text into plain strings.\n",
    "\n",
    "def text_cleaner(website):\n",
    "    try:\n",
    "        html = urllib.request.urlopen(urllib.request.Request(website, headers={'User-Agent': 'Mozilla/5.0'})).read()\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split())\n",
    "        text = ' '.join(chunks)\n",
    "        bytes(text, \"utf-8\").decode(\"unicode_escape\")\n",
    "        text = bytes(text, \"utf-8\").decode(\"unicode_escape\")\n",
    "        text = re.sub(\"[-:.!,*+%?//#Â·$;|]\",\" \", text)\n",
    "    except:\n",
    "        text = 'Unknown'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills_info_test(city = None, state = None, job_title = None):\n",
    "    final_job = str(job_title)\n",
    "    columns = [\"job_title\",\"job_link\",\"job_description\",\"company_name\",\"location\",\"summary\",\"salary\"]\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    num = (len-(df)+1)\n",
    "    \n",
    "     # find out how many jobs there were\n",
    "\n",
    "    final_job = str(job_title)\n",
    "    \n",
    "    # Make sure the city specified works properly if it has more than one word (such as San Francisco)\n",
    "    if city is not None:\n",
    "        final_city = city.split() \n",
    "        final_city = '+'.join(word for word in final_city)\n",
    "        final_site_list = ['http://ca.indeed.com/jobs?q=', final_job, '&l=', final_city,\n",
    "                    '%2C+', state] # Join all of our strings together so that indeed will search correctly\n",
    "    else:\n",
    "        final_site_list = ['http://ca.indeed.com/jobs?q=\"', final_job, '\"']\n",
    "\n",
    "    # Merge the html address together into one string\n",
    "    final_site = ''.join(final_site_list) \n",
    "\n",
    "    base_url = 'http://ca.indeed.com'\n",
    "    \n",
    "    for start in range(0,200,10):\n",
    "    \n",
    "    # Make sure the city specified works properly if it has more than one word (such as San Francisco)\n",
    "    \n",
    "        if city is not None:\n",
    "            final_city = city.split() \n",
    "            final_city = '+'.join(word for word in final_city)\n",
    "            \n",
    "            # Join all of our strings together so that indeed will search correctly\n",
    "            \n",
    "            final_site_list = ['http://ca.indeed.com/jobs?q=', final_job, '&l=', final_city,\n",
    "                    '%2C+', state,'&start=',str(start)] \n",
    "        else:\n",
    "            final_site_list = ['http://ca.indeed.com/jobs?q=\"', final_job, '\"','&start=', str(start)]\n",
    "\n",
    "        final_site = ''.join(final_site_list) # Merge the html address together into one string\n",
    "        \n",
    "        print ('The current site is '+ final_site)\n",
    "    \n",
    "        try:\n",
    "            html = requests.get(final_site, headers = headers()) # Open up the front page of our search first\n",
    "        except:\n",
    "            print('That city/state combination did not have any jobs. Exiting . . .') # In case the city is invalid\n",
    "            return\n",
    "        \n",
    "        # Get the html from the first page\n",
    "        \n",
    "        soup = BeautifulSoup(html.text, 'html.parser') \n",
    "    \n",
    "        job_link_area = soup.find(id = 'resultsCol')\n",
    "            \n",
    "        for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "            \n",
    "            # row num for index of job posting in dataframe\n",
    "            job_post = []\n",
    "            num = (len(df)+1)\n",
    "        \n",
    "            # grabbing job title\n",
    "        \n",
    "            for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "                job_post.append(a[\"title\"])\n",
    "        \n",
    "            # grabbing job link\n",
    "            job_descriptions = [] \n",
    "            for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "                job_post.append(str(base_url) + str(a[\"href\"]))\n",
    "                \n",
    "                final_description = text_cleaner(str(base_url) + str(a['href']))\n",
    "                job_post.append(final_description)\n",
    "            \n",
    "            # company name\n",
    "        \n",
    "            company = div.find_all(name = \"span\", attrs = {\"class\":\"company\"})\n",
    "        \n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip())\n",
    "            else:\n",
    "                sec_try = div.find_all(name = \"span\", attrs = {\"class\":\"result-link-source\"})\n",
    "            \n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text)\n",
    "                \n",
    "            #  location name\n",
    "        \n",
    "            c = div.findAll('span',attrs = {'class':'location'})\n",
    "        \n",
    "            for span in c:\n",
    "            \n",
    "                job_post.append(span.text)\n",
    "        \n",
    "            # summary text\n",
    "        \n",
    "            d = div.findAll('span', attrs = {'class':'summary'})\n",
    "            for span in d:\n",
    "                job_post.append(span.text.strip())\n",
    "                \n",
    "            # grabbing salary\n",
    "    \n",
    "            try:\n",
    "                job_post.append(div.find('nobr').text)\n",
    "        \n",
    "            except:\n",
    "                try:\n",
    "                    div_2 = div.find(name = 'div', attrs = {\"class\":\"sjcl\"})\n",
    "                    div_3 = div_2.find(\"div\")\n",
    "                    job_post.append(div_3.text.strip())\n",
    "                except:\n",
    "                    job_post.append(\"Nothing_Found\")\n",
    "                \n",
    "            #appending list of job post to a data frame at index num\n",
    "        \n",
    "            df.loc[num] = job_post\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: invalid escape sequence '\\:'\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: invalid escape sequence '\\:'\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=10\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=20\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=30\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=40\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=50\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=60\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=70\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=80\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=90\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=100\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=110\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=120\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=130\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=140\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=150\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=160\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=170\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=180\n",
      "The current site is http://ca.indeed.com/jobs?q=Data+Scientist&l=North+York%2C+ON&start=190\n"
     ]
    }
   ],
   "source": [
    "df1 = skills_info_test(city = 'hamilton', state = 'ON', job_title = \"Data+Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(a)[0:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv('file_save/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = skills_info_test(city = 'Toronto', state = 'ON', job_title = \"Data+Engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = skills_info_test(city = 'Toronto', state = 'ON', job_title = \"Accounting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
